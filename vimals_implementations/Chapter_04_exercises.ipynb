{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31b7a13-bc2f-48e5-a09b-84b1f5f85d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "387e2667-b26d-4d97-ac18-ee5d218fba21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "print(bs.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b6720f-d9aa-4461-b5e6-09bfc037618f",
   "metadata": {},
   "source": [
    "If you want to use a more advanced parser, you can use lxml. Note, you will have to install this first:\n",
    "```\n",
    "pip install lxml\n",
    "```\n",
    "\n",
    "Then you can do the following to parse the above (must restart jupyter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06aeca10-fbd1-43e0-989b-78bf1df2cf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'lxml')\n",
    "print(bs.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b05095-587a-4a0d-88da-ee2a292a18e2",
   "metadata": {},
   "source": [
    "Another popular parser to use is html5lib. It is, however, slower than lxml and html.parser.\n",
    "\n",
    "It can be installed using:\n",
    "```\n",
    "pip install html5lib\n",
    "```\n",
    "\n",
    "Then you can do the following (must restart Jupyter first):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f495bc-b768-41c7-89b5-8748b81c9fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html5lib')\n",
    "print(bs.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af472e81-a94c-427a-8ee0-b93a19141701",
   "metadata": {},
   "source": [
    "Handling errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87156b66-d3c0-484e-bf26-fc3b4a9056f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It Worked!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "except URLError as e:\n",
    "    print(\"The server could not be found!\")\n",
    "else:\n",
    "    print(\"It Worked!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7751a8c-0e10-4224-9883-32f2110d9506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'someTag'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(bs\u001b[38;5;241m.\u001b[39msomeBullshitTagThatDoesntExist)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Should return an error\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msomeBullshitTagThatDoesntExist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msomeTag\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'someTag'"
     ]
    }
   ],
   "source": [
    "# Should return None\n",
    "print(bs.someBullshitTagThatDoesntExist)\n",
    "\n",
    "#Should return an error\n",
    "print(bs.someBullshitTagThatDoesntExist.someTag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "195ee8ca-27f3-4b21-b65a-06b0b3b98a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag was not found\n"
     ]
    }
   ],
   "source": [
    "# Handling problem of non-existent tag\n",
    "try:\n",
    "    badContent = bs.someBullshit.anotherTag\n",
    "except AttributeError as e:\n",
    "    print(\"Tag was not found\")\n",
    "else:\n",
    "    if badContent == None:\n",
    "        print(\"Tag was not found\")\n",
    "    else:\n",
    "        print(badContent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7735d9a1-55cf-42cb-98d1-71bb9f579805",
   "metadata": {},
   "source": [
    "The same above scraper, now written in a new way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d961dc2f-d238-4064-a456-75c78e9a46dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except (HTTPError, URLError) as e:\n",
    "        return None\n",
    "    try:\n",
    "        bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "        title = bs.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "\n",
    "title = getTitle('http://www.pythonscraping.com/pages/page1.html')\n",
    "if title == None:\n",
    "    print(\"Title could not be found\")\n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8216c6b-cc62-4e8f-9ee3-c687ffe83580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
